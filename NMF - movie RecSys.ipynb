{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1f49b8-32c2-4c61-8560-e245c12738c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.spatial.distance import jaccard, cosine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9ad92c-7cc9-4a50-8fb6-854602288b7f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MV_users = pd.read_csv('../Files/data/users.csv')\n",
    "MV_movies = pd.read_csv('../Files/data/movies.csv')\n",
    "train = pd.read_csv('../Files/data/train.csv')\n",
    "test = pd.read_csv('../Files/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706bc212-23b9-450a-8955-070c12320996",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "class RecSys():\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.allusers = list(self.data.users['uID'])\n",
    "        self.allmovies = list(self.data.movies['mID'])\n",
    "        self.genres = list(self.data.movies.columns.drop(['mID', 'title', 'year']))\n",
    "        self.mid2idx = dict(zip(self.data.movies.mID,list(range(len(self.data.movies)))))\n",
    "        self.uid2idx = dict(zip(self.data.users.uID,list(range(len(self.data.users)))))\n",
    "        self.Mr=self.rating_matrix()\n",
    "        self.Mm=None \n",
    "        self.sim=np.zeros((len(self.allmovies),len(self.allmovies)))\n",
    "        \n",
    "    def rating_matrix(self):\n",
    "        \"\"\"\n",
    "        Convert the rating matrix to numpy array of shape (#allusers,#allmovies)\n",
    "        \"\"\"\n",
    "        ind_movie = [self.mid2idx[x] for x in self.data.train.mID] \n",
    "        ind_user = [self.uid2idx[x] for x in self.data.train.uID]\n",
    "        rating_train = list(self.data.train.rating)\n",
    "        \n",
    "        return coo_matrix((rating_train, (ind_user, ind_movie)), shape=(len(self.allusers), len(self.allmovies))).toarray()\n",
    "\n",
    "    def fit(self, **kwargs):\n",
    "        model = NMF(**kwargs)\n",
    "        self.W = model.fit_transform(self.Mr)\n",
    "        self.H = model.components_\n",
    "        self.generated_rankings = np.dot(self.W, self.H)   \n",
    "    \n",
    "    \n",
    "    def predict(self):\n",
    "        test_predictions = []\n",
    "        for i in range(len(self.data.test)):\n",
    "            uid = self.data.test.uID[i]\n",
    "            mid = self.data.test.mID[i]\n",
    "            rank_for_uid_mid = self.generated_rankings[self.uid2idx[uid], self.mid2idx[mid]]\n",
    "            test_predictions.append(rank_for_uid_mid)\n",
    "        return np.array(test_predictions)\n",
    "        \n",
    "    def rmse(self,yp):\n",
    "        yp[np.isnan(yp)]=3\n",
    "        yt=np.array(self.data.test.rating)\n",
    "        return np.sqrt(((yt-yp)**2).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8537a16-b572-4f24-a035-c69089484a0d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(MV_users, MV_movies, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437c1a0a-b141-4460-bd9b-6fdd0a35302f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "sample_train = train[:300]\n",
    "sample_test = test[:300]\n",
    "sample_MV_users = MV_users[(MV_users.uID.isin(sample_train.uID)) | (MV_users.uID.isin(sample_test.uID))]\n",
    "sample_MV_movies = MV_movies[(MV_movies.mID.isin(sample_train.mID)) | (MV_movies.mID.isin(sample_test.mID))]\n",
    "sample_data = Data(sample_MV_users, sample_MV_movies, sample_train, sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f95f14ef-d1c7-434a-8584-12917d79a7e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arturtanona/Documents/coursera/unsupervised-machine-learning/week4/old-one/venv/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:1200: FutureWarning: The default value of `n_components` will change from `None` to `'auto'` in 1.6. Set the value of `n_components` to `None` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0387445821997803\n"
     ]
    }
   ],
   "source": [
    "rs = RecSys(data)\n",
    "yp = rs.fit()\n",
    "yp = rs.predict()\n",
    "\n",
    "print(rs.rmse(yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd21c82-7dca-4514-8a00-dcf52847751a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "|Method|RMSE|\n",
    "|:----|:--------:|\n",
    "|Baseline, $Y_p$=3| 1.2585510334053043 |\n",
    "|Baseline, $Y_p=\\mu_u$| 1.0352910334228647 |\n",
    "|Content based, item-item| 1.0128116783754684 |\n",
    "|Collaborative, cosine| 1.0301524420757868 |\n",
    "|Collaborative, jaccard, $M_r\\geq 3$| 0.9819058692126349 |\n",
    "|Collaborative, jaccard, $M_r\\geq 1$| 0.991363571262366 |\n",
    "|Collaborative, jaccard, $M_r$| 0.9509126236828654 |\n",
    "|NMF| 3.038744|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3366e94b-fa4f-48a1-aee2-39d6efa952c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Discussion\n",
    "\n",
    "We can definetely see that NMF has a very poor performance on the dataset.\n",
    "\n",
    "RMSE, which stands for Root Mean Squared Error, is a widely used metric for assessing the performance of predictive models, particularly in regression and recommendation systems. This metric quantifies the average magnitude of errors between the predicted values and the actual observed values.\n",
    "\n",
    "- A lower RMSE indicates that the predicted values are closer to the actual values, reflecting better model accuracy.\n",
    "- A higher RMSE signifies greater discrepancies between the predicted values and the actual values, pointing to poorer model performance.\n",
    "\n",
    "When dealing with sparse datasets, NMF may struggle to identify meaningful patterns, potentially resulting in a higher RMSE due to a lack of sufficient information. Additionally, NMF can be sensitive to the initialization of matrices; inappropriate initial values may cause the algorithm to converge to a local minimum, leading to suboptimal outcomes.\n",
    "\n",
    "In scenarios involving sparse datasets, collaborative filtering methods, such as those based on Jaccard similarity, may be more effective in handling sparsity by utilizing more insightful user-item interactions.\n",
    "\n",
    "The NMF struggles in this scenario because it interprets the unknown ratings as zeros within the matrix being factorized (X in the equation X=WH). By default, we utilize the Frobenius norm, and assigning a value of zero when the actual value should be between 1 and 5 skews the gradient. This results in inaccurate updates to matrices W and H.\n",
    "\n",
    "I recommend starting by altering the loss function to Kullback-Leibler divergence, as this approach proved effective in the BBC assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356b59d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
